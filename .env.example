# kg_ae configuration
# Copy to .env and modify as needed

# HuggingFace token (required for gated models like Phi-4)
# Get yours at: https://huggingface.co/settings/tokens
HF_TOKEN=hf_your_token_here

# SQL Server connection
KG_AE_DB_SERVER=localhost
KG_AE_DB_NAME=kg_ae
KG_AE_DB_DRIVER=ODBC Driver 18 for SQL Server
KG_AE_DB_TRUSTED_CONNECTION=true

# For SQL auth (if not using Windows auth):
# KG_AE_DB_TRUSTED_CONNECTION=false
# KG_AE_DB_USERNAME=your_username
# KG_AE_DB_PASSWORD=your_password

# Data directory
KG_AE_DATA_DIR=data

# Logging
KG_AE_LOG_LEVEL=INFO

# =============================================================================
# LLM Configuration (Groq Cloud - Recommended)
# =============================================================================
# Get your API key at: https://console.groq.com/keys

GROQ_API_KEY=gsk_your_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Temperature settings (lower = more deterministic)
GROQ_PLANNER_TEMPERATURE=0.1
GROQ_NARRATOR_TEMPERATURE=0.3

# Token limits
GROQ_PLANNER_MAX_TOKENS=4096
GROQ_NARRATOR_MAX_TOKENS=8192

# Alternative Groq models:
# GROQ_MODEL=llama-3.1-8b-instant      # Faster, lower quality
# GROQ_MODEL=mixtral-8x7b-32768        # Good balance
# GROQ_MODEL=gemma2-9b-it              # Google's model

# =============================================================================
# LLM Configuration (Local llama.cpp - Alternative)
# =============================================================================
# Uncomment to use local models instead of Groq

# PLANNER_BASE_URL=http://localhost:8080/v1
# PLANNER_MODEL=phi-4-mini
# PLANNER_TEMPERATURE=0.1
# PLANNER_MAX_TOKENS=4096

# NARRATOR_BASE_URL=http://localhost:8081/v1
# NARRATOR_MODEL=phi-4
# NARRATOR_TEMPERATURE=0.3
# NARRATOR_MAX_TOKENS=8192
